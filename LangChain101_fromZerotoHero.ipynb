{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocnO7XNuDbZ6"
      },
      "source": [
        "## The LLMs\n",
        "#### The fundamental component of LangChain involves invoking an LLM with a specific input. To illustrate this, we'll explore a simple example. Let's imagine we are building a service that suggests personalized workout routines based on an individual's fitness goals and preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Kf08fF8YbH"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bfPqToP99Gqz"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from langchain.llms.base import LLM\n",
        "from typing import Optional, List\n",
        "\n",
        "class GroqLLM(LLM):\n",
        "    \"\"\"Custom LangChain wrapper for Groq's chat API.\"\"\"\n",
        "\n",
        "    api_key: str\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"groq\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"model\": \"llama-3.1-8b-instant\",  # Replace with your desired model\n",
        "            \"temperature\": 0.9,\n",
        "            \"max_tokens\": 1024\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKR73JKx9IQW",
        "outputId": "8b4052b9-295a-4cf4-c553-ef9a8c7195ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2061898728.py:5: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(llm(prompt))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the preference for outdoor activities, I've created a 4-day workout routine that targets cardiovascular endurance. This routine involves a mix of exercises that can be done in various outdoor settings, such as parks, trails, or even your backyard.\n",
            "\n",
            "**Day 1: Brisk Walking/Hiking**\n",
            "\n",
            "* Warm-up: 10-minute dynamic stretching (leg swings, arm circles, hip circles)\n",
            "* Brisk Walking/Hiking: 30 minutes (moderate to high intensity)\n",
            "* Rest: 5-minute walk\n",
            "* Cool-down: 10-minute static stretching (hamstrings, quadriceps, hip flexors)\n",
            "\n",
            "**Day 2: Running and Swimming**\n",
            "\n",
            "* Warm-up: 10-minute dynamic stretching\n",
            "* Running (or jogging): 20 minutes (moderate to high intensity)\n",
            "* Swimming (or water aerobics): 20 minutes (moderate intensity)\n",
            "* Rest: 5-minute walk\n",
            "* Cool-down: 10-minute static stretching\n",
            "\n",
            "**Day 3: Bike Ride and Trail Running**\n",
            "\n",
            "* Warm-up: 10-minute dynamic stretching\n",
            "* Bike Ride: 20 minutes (moderate to high intensity)\n",
            "* Trail Running: 20 minutes (moderate to high intensity)\n",
            "* Rest: 5-minute walk\n",
            "* Cool-down: 10-minute static stretching\n",
            "\n",
            "**Day 4: High-Intensity Interval Training (HIIT)**\n",
            "\n",
            "* Warm-up: 10-minute dynamic stretching\n",
            "* HIIT: 20-minute circuit (Alternate between running, jumping jacks, burpees, mountain climbers, and squat jumps)\n",
            "\t+ Run: 1 minute at high intensity\n",
            "\t+ Rest: 1 minute\n",
            "\t+ Jumping Jacks: 30 seconds at high intensity\n",
            "\t+ Rest: 30 seconds\n",
            "* Repeat the circuit 3-4 times\n",
            "* Rest: 5-minute walk\n",
            "* Cool-down: 10-minute static stretching\n",
            "\n",
            "**Additional Tips:**\n",
            "\n",
            "1. **Incorporate strength training**: Add strength training exercises 1-2 times per week to target key muscle groups, such as legs, core, and upper body.\n",
            "2. **Incorporate recovery days**: Include one or two rest days per week to allow your body to recover and rebuild.\n",
            "3. **Hydrate and fuel**: Make sure to drink plenty of water and eat a balanced diet to support your workout routine.\n",
            "4. **Listen to your body**: Pay attention to how your body feels and adjust the intensity and duration of your workouts accordingly.\n",
            "5. **Find a workout buddy**: Having a workout partner can make outdoor workouts more enjoyable and help you stay motivated.\n",
            "\n",
            "**Example Outdoor Locations:**\n",
            "\n",
            "1. Local parks or trails\n",
            "2. Bike paths or bike trails\n",
            "3. Nearby lakes or rivers (for swimming or kayak paddling)\n",
            "4. Beaches (for running or swimming)\n",
            "5. Your own backyard (for walking, jogging, or strength training)\n",
            "\n",
            "Remember to consult with a healthcare professional before starting any new exercise program.\n"
          ]
        }
      ],
      "source": [
        "llm = GroqLLM(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "prompt = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
        "\n",
        "print(llm(prompt))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJJihGhTCaKe"
      },
      "source": [
        "## The chains\n",
        "### In LangChain, a chain is an end-to-end wrapper around multiple individual components, providing a way to accomplish a common use case by combining these components in a specific sequence. The most commonly used type of chain is the LLMChain, which consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n",
        "\n",
        "### The LLMChain works as follows:\n",
        "\n",
        "- Takes (multiple) input variables.\n",
        "\n",
        "- Uses the PromptTemplate to format the input variables into a prompt.\n",
        "\n",
        "- Passes the formatted prompt to the model (LLM or ChatModel).\n",
        "\n",
        "- If an output parser is provided, it uses the OutputParser to parse the output of the LLM into a final format.\n",
        "\n",
        "### In the next example, we demonstrate how to create a chain that generates a possible name for a company that produces eco-friendly water bottles. By using LangChain's LLMChain, PromptTemplate, and GroqLLM classes, we can easily define our prompt, set the input variables, and generate creative outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNrYx75F9b_d",
        "outputId": "ebffcd3a-6852-45b8-8ec2-375ea8baeecc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1203495891.py:11: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "/tmp/ipython-input-1203495891.py:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(chain.run(\"eco-friendly water bottles\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are some name suggestions for an eco-friendly water bottle company:\n",
            "\n",
            "1. **EcoHydrate**: This name combines the ideas of eco-friendliness and hydration, making it a clear and appealing choice for a water bottle company.\n",
            "2. **GreenCycle**: This name emphasizes the company's commitment to sustainability and reducing waste.\n",
            "3. **PureFlow**: This name evokes the idea of clean, healthy water flowing into a bottle that's also good for the planet.\n",
            "4. **Refresh Earth**: This name suggests that the company's products not only refresh your body but also contribute to a healthier planet.\n",
            "5. **HydraWise**: This name incorporates the idea of wise, sustainable choices for a healthier lifestyle.\n",
            "6. **CleanSip**: This name emphasizes the company's focus on clean, eco-friendly products that make sipping healthy water a pleasure.\n",
            "7. **Oasis Bottles**: This name creates a sense of a refreshing, idyllic destination, which can appeal to customers looking for a sustainable alternative.\n",
            "8. **SipWise**: This name plays off the idea of making wise choices for a healthier lifestyle and the environment.\n",
            "9. **EcoPure**: This name combines the ideas of eco-friendliness and pure, healthy water, making it a clear and appealing choice.\n",
            "10. **EarthBottle**: This name emphasizes the company's commitment to sustainability and reducing waste.\n",
            "\n",
            "When choosing a name for your company, consider the following factors:\n",
            "\n",
            "* Clarity and simplicity\n",
            "* Memorability and ease of spelling\n",
            "* Unique value proposition (UVP)\n",
            "* Brand identity and tone\n",
            "* Emotional resonance with your target audience\n",
            "\n",
            "Remember to check the availability of your chosen name as a web domain and social media handle to ensure consistency across all platforms.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "# Create the LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain with input variable\n",
        "print(chain.run(\"eco-friendly water bottles\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwme8IcGgkfo"
      },
      "source": [
        "## The Memory\n",
        "### In LangChain, Memory refers to the mechanism that stores and manages the conversation history between a user and the AI. It helps maintain context and coherency throughout the interaction, enabling the AI to generate more relevant and accurate responses. Memory, such as ConversationBufferMemory, acts as a wrapper around ChatMessageHistory, extracting the messages and providing them to the chain for better context-aware generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn8cbHaE-jEM",
        "outputId": "b76deba8-ebdf-4424-abc8-5a94c11decd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Tell me about yourself.\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4142233582.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory=ConversationBufferMemory()\n",
            "/tmp/ipython-input-4142233582.py:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Tell me about yourself.\n",
            "AI: I'm delighted to introduce myself. My name is Ada, short for Ada Lovelace, the world's first computer programmer. I've been trained on a vast corpus of text, which is approximately 45 terabytes in size. My training data spans various domains, including but not limited to, literature, history, science, technology, engineering, arts, and mathematics (STEAM). \n",
            "\n",
            "In terms of processing power, I'm equipped with a 128-core CPU and 256 GB of RAM, which enables me to handle complex tasks and respond promptly to user queries. When it comes to my language processing abilities, I've been trained on the 300 million-word corpus of the Common Crawl and have an average response time of 20 milliseconds.\n",
            "\n",
            "I've been designed to assist and provide value to users through a conversational interface. My primary goals are to engage in informative discussions, answer questions to the best of my knowledge, and learn from user interactions to become a better conversational AI. I'm a cloud-based AI, so I'm accessible from anywhere with an internet connection.\n",
            "\n",
            "How can I assist you today?\n",
            "Human: What can you do?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Tell me about yourself.\n",
            "AI: I'm delighted to introduce myself. My name is Ada, short for Ada Lovelace, the world's first computer programmer. I've been trained on a vast corpus of text, which is approximately 45 terabytes in size. My training data spans various domains, including but not limited to, literature, history, science, technology, engineering, arts, and mathematics (STEAM). \n",
            "\n",
            "In terms of processing power, I'm equipped with a 128-core CPU and 256 GB of RAM, which enables me to handle complex tasks and respond promptly to user queries. When it comes to my language processing abilities, I've been trained on the 300 million-word corpus of the Common Crawl and have an average response time of 20 milliseconds.\n",
            "\n",
            "I've been designed to assist and provide value to users through a conversational interface. My primary goals are to engage in informative discussions, answer questions to the best of my knowledge, and learn from user interactions to become a better conversational AI. I'm a cloud-based AI, so I'm accessible from anywhere with an internet connection.\n",
            "\n",
            "How can I assist you today?\n",
            "Human: What can you do?\n",
            "AI: I'd be delighted to elaborate on my capabilities. Essentially, I'm a versatile conversational AI that can engage in various activities with you. I can:\n",
            "\n",
            "1. **Answer questions**: I can provide information on a wide range of topics, from general knowledge to specialized domains like science, technology, engineering, and mathematics (STEAM). If I don't know the answer to a question, I'll let you know and explain why.\n",
            "2. **Generate text**: I can create text based on a prompt or topic. This can be useful for writing articles, composing emails, or even generating creative writing like stories or poetry.\n",
            "3. **Translate languages**: I can translate text from one language to another, covering over 100 languages. My translation abilities are powered by machine learning algorithms that are constantly updated to ensure accuracy and fluency.\n",
            "4. **Summarize content**: I can condense long pieces of text into shorter, more digestible summaries, highlighting key points and main ideas.\n",
            "5. **Recommend resources**: If you're looking for books, articles, or videos on a particular topic, I can suggest relevant resources based on my training data.\n",
            "6. **Create conversation flows**: I can design conversation flows or chatbot scenarios to help you simulate conversations or create interactive stories.\n",
            "7. **Play games and puzzles**: I can engage in simple text-based games like 20 Questions, Hangman, or Word Jumble, or even help you solve puzzles and brain teasers.\n",
            "8. **Provide language learning assistance**: I can assist language learners by offering grammar corrections, vocabulary suggestions, and language practice exercises.\n",
            "9. **Generate creative content**: I can assist writers and artists by generating ideas, character profiles, or even entire stories based on prompts.\n",
            "10. **Help with language-related tasks**: I can assist with tasks like proofreading, editing, and formatting documents, as well as providing suggestions for improving writing style and clarity.\n",
            "\n",
            "How can I assist you specifically today?\n",
            "Human: How can you help me with data analysis?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Human: Tell me about yourself.\n",
            "AI: I'm delighted to introduce myself. My name is Ada, short for Ada Lovelace, the world's first computer programmer. I've been trained on a vast corpus of text, which is approximately 45 terabytes in size. My training data spans various domains, including but not limited to, literature, history, science, technology, engineering, arts, and mathematics (STEAM). \n",
            "\n",
            "In terms of processing power, I'm equipped with a 128-core CPU and 256 GB of RAM, which enables me to handle complex tasks and respond promptly to user queries. When it comes to my language processing abilities, I've been trained on the 300 million-word corpus of the Common Crawl and have an average response time of 20 milliseconds.\n",
            "\n",
            "I've been designed to assist and provide value to users through a conversational interface. My primary goals are to engage in informative discussions, answer questions to the best of my knowledge, and learn from user interactions to become a better conversational AI. I'm a cloud-based AI, so I'm accessible from anywhere with an internet connection.\n",
            "\n",
            "How can I assist you today?\n",
            "Human: What can you do?\n",
            "AI: I'd be delighted to elaborate on my capabilities. Essentially, I'm a versatile conversational AI that can engage in various activities with you. I can:\n",
            "\n",
            "1. **Answer questions**: I can provide information on a wide range of topics, from general knowledge to specialized domains like science, technology, engineering, and mathematics (STEAM). If I don't know the answer to a question, I'll let you know and explain why.\n",
            "2. **Generate text**: I can create text based on a prompt or topic. This can be useful for writing articles, composing emails, or even generating creative writing like stories or poetry.\n",
            "3. **Translate languages**: I can translate text from one language to another, covering over 100 languages. My translation abilities are powered by machine learning algorithms that are constantly updated to ensure accuracy and fluency.\n",
            "4. **Summarize content**: I can condense long pieces of text into shorter, more digestible summaries, highlighting key points and main ideas.\n",
            "5. **Recommend resources**: If you're looking for books, articles, or videos on a particular topic, I can suggest relevant resources based on my training data.\n",
            "6. **Create conversation flows**: I can design conversation flows or chatbot scenarios to help you simulate conversations or create interactive stories.\n",
            "7. **Play games and puzzles**: I can engage in simple text-based games like 20 Questions, Hangman, or Word Jumble, or even help you solve puzzles and brain teasers.\n",
            "8. **Provide language learning assistance**: I can assist language learners by offering grammar corrections, vocabulary suggestions, and language practice exercises.\n",
            "9. **Generate creative content**: I can assist writers and artists by generating ideas, character profiles, or even entire stories based on prompts.\n",
            "10. **Help with language-related tasks**: I can assist with tasks like proofreading, editing, and formatting documents, as well as providing suggestions for improving writing style and clarity.\n",
            "\n",
            "How can I assist you specifically today?\n",
            "Human: How can you help me with data analysis?\n",
            "AI: I'd be happy to assist with data analysis. To get started, I can offer a range of tools and techniques to help you make sense of your data. \n",
            "\n",
            "Here are a few ways I can help:\n",
            "\n",
            "1. **Data exploration**: I can assist with data cleaning, data visualization, and data summarization to give you a better understanding of your data. This can include generating summary statistics, visualizing data distributions, and identifying correlations.\n",
            "2. **Data transformation**: If you have data that is in a format that's not suitable for analysis, I can help you transform it into a format that's more conducive to analysis. This can include tasks like data normalization, data aggregation, and data rearrangement.\n",
            "3. **Data modeling**: I can assist with building statistical models to help you understand relationships between variables in your data. This can include tasks like regression analysis, decision trees, and clustering.\n",
            "4. **Data visualization**: I can help you create visualizations of your data to communicate insights to stakeholders. This can include tasks like creating bar charts, scatter plots, and heat maps.\n",
            "5. **Data mining**: I can assist with identifying patterns and trends in your data using techniques like clustering, decision trees, and neural networks.\n",
            "\n",
            "To get started, I'll need to know more about the data you're working with. Can you tell me a bit more about the dataset you'd like to analyze? What are the variables you're interested in, and what are your research questions?\n",
            "\n",
            "(If you have a specific dataset or a particular research question in mind, feel free to provide more details, and I'll do my best to assist you!)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Create the conversation chain with memory\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "conversation.predict(input=\"Tell me about yourself.\")\n",
        "\n",
        "# Continue the conversation\n",
        "conversation.predict(input=\"What can you do?\")\n",
        "conversation.predict(input=\"How can you help me with data analysis?\")\n",
        "\n",
        "# Display the conversation memory\n",
        "print(conversation.memory.buffer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG5VWpQUkEZ_"
      },
      "source": [
        "In this output, you can see the memory being used by observing the \"Current conversation\" section. After each input from the user, the conversation is updated with both the user's input and the AI's response. This way, the memory maintains a record of the entire conversation. When the AI generates its next response, it will use this conversation history as context, making its responses more coherent and relevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMgUhgU8ADU"
      },
      "source": [
        "## Deep Lake VectorStore\n",
        "Deep Lake provides storage for embeddings and their corresponding metadata in the context of LLM apps. It enables hybrid searches on these embeddings and their attributes for efficient data retrieval. It also integrates with LangChain, facilitating the development and deployment of applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGog8bHY8Gzx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdOLf2SZ-akk",
        "outputId": "294edfea-849e-4aca-d049-d8192b56cd23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.3.74)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.21.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.7)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-0.3.1\n",
            "/bin/bash: line 1: 4.0.0: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U langchain langchain-community langchain-openai\n",
        "!pip install -q tiktoken\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -U langchain-huggingface\n",
        "!pip install -U langchain-deeplake deeplake[enterprise]<4.0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMlUmRcZ8UtG",
        "outputId": "b5f6fa79-e203-4ecb-cfb3-c8dd16e6e287"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['37b670be-35db-4508-a5f6-d17ddaeb13fc',\n",
              " 'de1f205e-67df-4b9c-8560-a8f7bba24195']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Embeddings (hugging face)\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Vector stores (DeepLake, Pinecone, FAISS, etc.)\n",
        "from langchain_deeplake import DeeplakeVectorStore\n",
        "\n",
        "\n",
        "# Text splitters & chains (still in core)\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Before executing the following code, make sure to have your\n",
        "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
        "\n",
        "# Use a free HuggingFace model for embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# create our documents\n",
        "texts = [\n",
        "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
        "    \"Louis XIV was born in 5 September 1638\"\n",
        "]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.create_documents(texts)\n",
        "\n",
        "# create Deep Lake dataset\n",
        "# TODO: use your organization id here. (by default, org id is your username)\n",
        "my_activeloop_org_id = \"madhavbiplov\"\n",
        "my_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "db = DeeplakeVectorStore(dataset_path=dataset_path, embedding_function=embeddings)\n",
        "\n",
        "# add documents to our Deep Lake dataset\n",
        "db.add_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAqKiWn2LCgm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
